LLM Chatbot â€“ Spring Boot (Java)

A Spring Bootâ€“based LLM Chatbot that integrates with the OpenAI Chat Completion API to simulate an IT Customer Support Assistant, built with production-oriented backend design principles.

ğŸ“Œ Project Overview

This project demonstrates how to integrate Large Language Models (LLMs) into a Java backend application using Spring Boot, focusing on:

1. Clean architecture

2. Secure configuration management

3. Predictable LLM behavior

4. Handling real-world latency and timeouts

5. IDE-only execution using Spring Tool Suite (STS)

Rather than a quick demo, this project is designed as a foundation for enterprise-grade GenAI systems.

ğŸ¯ What This Chatbot Does

1. Accepts a user query

2. Sends the query to the OpenAI Chat Completion API

3. Applies system instructions so the model behaves like an IT support executive

4. Controls response randomness and length

5. Returns a concise, deterministic response

ğŸ§  Key Features

--> OpenAI Chat API integration

--> Java + Spring Boot Backend

--> Secure API key handling (no hardcoding)

--> Configurable max_tokens

--> Configurable temperature

--> Custom HTTP timeouts

--> Clean separation of concerns

--> IDE-only execution (Spring Tool Suite)

ğŸ—ï¸ Technology Stack


| Layer           | Technology                  |
| --------------- | --------------------------- |
| Language        | Java 17                     |
| Framework       | Spring Boot                 |
| Build Tool      | Maven                       |
| HTTP Client     | OkHttp                      |
| JSON Parsing    | Gson                        |
| LLM Provider    | OpenAI                      |
| IDE             | Spring Tool Suite (Eclipse) |
| Version Control | Git + GitHub                |



ğŸ“ Project Structure

llm-chatbot-springboot
â”œâ”€â”€ src/main/java
â”‚   â”œâ”€â”€ IntentClassifier.java
â”‚   â”œâ”€â”€ Main.java
â”‚   â””â”€â”€ OpenAIClient.java
â”‚
â”œâ”€â”€ src/main/resources
â”œâ”€â”€ pom.xml
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


ğŸ§© Class Responsibilities
Main.java

 --> Application entry point

 --> Bootstraps the Spring context

OpenAIClient.java

 --> Core integration with OpenAI API

 --> Builds request payload (model, messages, tokens, temperature)

 --> Sends HTTP requests using OkHttp

 --> Parses and returns responses

 --> Applies timeout configuration

IntentClassifier.java

 --> Foundation for intent classification

 --> Designed for future routing and escalation logic

ğŸ§© High-Level Architecture

Client --> Spring Boot Application --> OpenAIClient --> OpenAI Chat Completion API



ğŸ”„ Request Flow

1. User sends a message

2. Spring Boot receives the request

3. OpenAIClient builds the prompt and configuration

4. Request is sent to OpenAI API

5. Response is parsed and returned

ğŸ” API Key Management (IMPORTANT)

This project does not store secrets in code or configuration files.

How to configure the API key in STS

1. Open Run â†’ Run Configurations

2. Select your Spring Boot Application

3. Go to the Environment tab

4. Add:
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxx


5. Click Apply â†’ Run

This ensures:

--> No secrets in GitHub

--> Safe collaboration

--> Production-aligned configuration

ğŸš€ Running the Application (STS Only)

No terminal required.

1. Open the project in Spring Tool Suite

2. Ensure Java 17 is selected

3. Configure OPENAI_API_KEY

4. Click Run

âš™ï¸ OpenAI Configuration
| Parameter   | Value           | Reason                               |
| ----------- | --------------- | ------------------------------------ |
| Model       | `gpt-3.5-turbo` | Stable baseline                      |
| max_tokens  | `200`           | Controls response length & cost      |
| temperature | `0.2`           | Deterministic, support-style replies |

â±ï¸ Timeout & Reliability Handling

LLM APIs can have variable latency.
This project configures custom HTTP timeouts to avoid hanging requests and improve reliability.

ğŸ›¡ï¸ Design Decisions

1. Environment variables for secrets: prevents leaks

2. Low temperature: reduces hallucinations

3. Stateless design: easier scaling

4. Explicit timeouts: production readiness

ğŸ¤ Interview Talking Points

--> Production-style LLM integration in Java

--> No hardcoded secrets

--> Controlled randomness and output size

--> Timeout handling for external AI APIs

--> Extensible design for future AI workflows

ğŸ“ˆ Planned Enhancements

--> Confidence scoring & escalation

--> Intent-based routing

--> Conversation memory

--> Retry & circuit-breaker logic

--> Streaming responses

--> Retrieval-Augmented Generation (RAG)

ğŸ§ª Who This Project Is For

--> Java Backend Developers

--> Engineers learning GenAI integration

--> System design interview preparation

--> Developers moving beyond simple API demos

ğŸ§‘â€ğŸ’» Author

Naman Jain
Java | Backend | GenAI

GitHub: https://github.com/namanjain775

ğŸ“„ License

For learning and demonstration purposes.

â­ Final Note

This project focuses on engineering discipline, not just calling an API.
It reflects how LLMs are integrated into real-world backend systems.
